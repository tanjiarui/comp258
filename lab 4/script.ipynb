{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "script",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "fuFEkzIC5mfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "codes, lines = list(), 1000\n",
        "for root, dirs, files in os.walk('fake tensorflow'):\n",
        "\tfor file in files:\n",
        "\t\tif file.find('.') != -1 and file.split('.')[1] == 'py':\n",
        "\t\t\tfile = open(os.path.join(root, file), 'r')\n",
        "\t\t\tfor line in file:\n",
        "\t\t\t\tif len(line) > 4:\n",
        "\t\t\t\t\tcodes.append(line)\n",
        "\t\t\t\t\tlines -= 1\n",
        "\t\t\t\tif lines == 0:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\tfile.close()\n",
        "\t\tif lines == 0:\n",
        "\t\t\tbreak\n",
        "\tif lines == 0:\n",
        "\t\tbreak"
      ],
      "metadata": {
        "id": "cWwm1lv15ocC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codes = ''.join(codes)\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(codes)\n",
        "n_steps, stride = 100, 1\n",
        "X, Y = list(), list()\n",
        "for i in range(0, len(codes) - n_steps, stride):\n",
        "\tX.append(tokenizer.texts_to_matrix(codes[i: i + n_steps], 'tfidf'))\n",
        "\tY.append(tokenizer.texts_to_matrix(codes[i + stride: i + n_steps + stride], 'tfidf'))\n",
        "X, Y = np.array(X), np.array(Y)\n",
        "del codes"
      ],
      "metadata": {
        "id": "fp-W8cN_5q8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\tinput_layer = tf.keras.Input(shape=(n_steps, len(tokenizer.index_word) + 1))\n",
        "\tnorm = tf.keras.layers.LayerNormalization()(input_layer)\n",
        "\tlstm = tf.keras.layers.LSTM(256, return_sequences=True, kernel_regularizer='l2')(norm)\n",
        "\tdense = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer='l2')(lstm)\n",
        "\tnorm = tf.keras.layers.LayerNormalization()(dense)\n",
        "\tattention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=4, kernel_regularizer='l2')(norm, norm)\n",
        "\toutput_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(tokenizer.index_word) + 1, activation='softmax'))(attention)\n",
        "\tmodel = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "yk2NXJGwswpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=2)\n",
        "model.fit(X, Y, validation_split=.2, epochs=10, callbacks=[early_stopping])\n",
        "model.save('model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45v54I4nsxZ8",
        "outputId": "bb99acca-8a76-4df2-9b7c-26d0ed3ef48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1162/1162 [==============================] - 478s 409ms/step - loss: 4.8117 - accuracy: 0.3535 - val_loss: 6.1971 - val_accuracy: 0.3527\n",
            "Epoch 2/10\n",
            "1162/1162 [==============================] - 473s 407ms/step - loss: 1.7936 - accuracy: 0.6054 - val_loss: 7.6396 - val_accuracy: 0.3659\n",
            "Epoch 3/10\n",
            "1162/1162 [==============================] - 473s 407ms/step - loss: 1.1533 - accuracy: 0.6531 - val_loss: 7.9081 - val_accuracy: 0.3696\n",
            "Epoch 00003: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f77b455bb50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "overfitting happened because the training set is not large enough. there is no more memory to generate more data. so, the code generation is poor."
      ],
      "metadata": {
        "id": "k59fartmAb0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HJRU7gWcAbyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '''\n",
        "def enable():\n",
        "  # Enables v2 behaviors.\n",
        "  _pywrap_tf2.enable(True)\n",
        "\n",
        "def disable():\n",
        "  # Disables v2 behaviors.\n",
        "  _pywrap_tf2.enable(False)\n",
        "\n",
        "@tf_export(\"__internal__.tf2.enabled\", v1=[])\n",
        "def enabled():\n",
        "  # Returns True iff TensorFlow 2.0 behavior should be enabled.\n",
        "  return _pywrap_tf2.is_enabled()'''\n",
        "query = tokenizer.texts_to_matrix(query[:100], 'tfidf')\n",
        "predict = model.predict(query.reshape([-1, query.shape[0], query.shape[1]])).squeeze()\n",
        "predict = [np.argmax(one_hot) for one_hot in predict]\n",
        "print(tokenizer.sequences_to_texts([predict]))"
      ],
      "metadata": {
        "id": "9NKTH9eQ172N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3134b0-c379-4957-93d7-59d2da1da65c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"s e f a f n c b l e d d f v v c c c c n a b l e s o v 2 b b e h a v i o r s a o ' p p p y w r a p t t f 2 0 e n a b l e ' e r u e n d d d e f i f i s a b l e s v v v n n d d d i s a b l e s e v 2 b b\"]\n"
          ]
        }
      ]
    }
  ]
}